{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6d3fad-2d20-4767-a564-1487f61c98cb",
   "metadata": {},
   "source": [
    "# 特徴量圧縮，学習モデル適用\n",
    "\n",
    "以後，訓練データ，検証データをまとめてギャラリーデータとする．また，テストデータにおけるトラックレット毎のサンプルの塊をそれぞれクエリとする．\n",
    "\n",
    "OSNetで得た外観特徴量を学習モデルに適用して，特徴量を圧縮する．以下のコードをinput_fileにギャラリーデータとテストデータをそれぞれ与えて，コードを実行する．\n",
    "\n",
    "# 出力csv\n",
    "- label\n",
    "- point_ID\n",
    "- file_name\n",
    "- 圧縮後特徴量ベクトル128次元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc5b38-7f7b-4c89-9a83-6a57466583ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力データに512次元の特徴ベクトルとした場合\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# モデルの定義\n",
    "class Net128(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net128, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 384)\n",
    "        self.fc2 = nn.Linear(384, 288)\n",
    "        self.bn1 = nn.BatchNorm1d(288)\n",
    "        self.fc3 = nn.Linear(288, 224)\n",
    "        self.dropout_1 = nn.Dropout(0.2)\n",
    "        self.fc4 = nn.Linear(224, 160)\n",
    "        self.dropout_2 = nn.Dropout(0.2)\n",
    "        self.fc5 = nn.Linear(160, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc6 = nn.Linear(128, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout_1(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "def normalize_features(features):\n",
    "    return features.apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=1)\n",
    "\n",
    "def transform_features(model, input_csv_path, output_csv_path):\n",
    "    # モデルのインスタンスを作成し、状態をロード\n",
    "    model.eval()  # 評価モードに設定\n",
    "\n",
    "    # CSVファイルからデータを読み込む\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    # 512次元の特徴量を取得\n",
    "    features = df.iloc[:, 3:-4]\n",
    "    features = normalize_features(features)\n",
    "    features_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # 低次元に変換\n",
    "    with torch.no_grad():\n",
    "        transformed_features = model(features_tensor)\n",
    "\n",
    "    # 結果をデータフレームに追加\n",
    "    for i in range(transformed_features.shape[1]):\n",
    "        column_name = f'dim{i + 1}'\n",
    "        df[column_name] = transformed_features[:, i].numpy()\n",
    "\n",
    "    # 3列目から514列目までを削除する（インデックス3から515）\n",
    "    df = df.drop(df.columns[3:515], axis=1)\n",
    "\n",
    "    # CSVとして保存\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = Net128()  # モデルのインスタンス化\n",
    "    model.load_state_dict(torch.load(\"./best_model_PML128_exp1_kouzumi.pth\"))  # モデルの状態をロード\n",
    "    input_file = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/filltered_feature_all_orient5_num_metric_with_exp1_koizumi.csv'\n",
    "    output_csv_path = 'C:/Users/sugie/PycharmProjects/pythonProject10/orient_tranceformed_data/tranceformed_data_all_orient5_num_128_triplet_OSNet_with_exp1_koizumi.csv'\n",
    "\n",
    "    transform_features(model, input_file, output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
